GraphBLAS/TODO_parallel.txt: Here are a list of the Source/*.c files that need
to be done in parallel.  I've roughly sorted them by priority and partly by the
low-hanging fruit (some will be quick to do).  You can find them all with:

cd GraphBLAS/Source
grep -r PARALLEL: .

Testing the parallel codes:  Most of my test suite is done through MATLAB
mexFunctions in the GraphBLAS/Test directory.  The mexFunctions link against
the GraphBLAS library, so do a "make install" and then use Test/testall.m
in MATLAB.

Alternatively: use the algorithms and main programs in LAGraph (BFS for now),
GraphBLAS/Demo (BFS, MIS, PageRank, triangle counting) and GraphBLAS/Extras
(triangle counting, k-truss, and all-k-truss).  The k-truss and all-k-truss do
lots of matrix-matrix multiplies.  Pagerank is a good test for mxv via "*FINE"
slice methods.  For the parallel qsort, use LAGraph/BuildMatrix/btest to test
the parallel performance.  See also Test/DNN.

A few methods use the GBI_parallel_for_each_vector(A) iterator, but most use
their own parallel for loop structure.  The more complex iterators (GBI2,
GBI2s, GBI3, GBI3s) can be ignored for now; they iterate over a set union of 2
or more lists.  They are currently not easily parallelizable and need to be
replaced with simpler loops to parallelize them.

All parallel methods need tuning and benchmarking.

----------------------------------------------------------------------
done:
----------------------------------------------------------------------

GB_transpose_ix.c
GB_transpose_op.c
GB_transpose_bucket.c
GB_extractTuples.c
GB_apply_op.c
GB_dup.c
GB_build.c
GB_builder.c:
GB_reduce_to_vector.c
GB_select.c
GB_selector.c
GB_transplant.c
GB_cast_array.c
GB_nvec_nonempty.c
GB_memcpy.c
GB_AxB_colscale.c
GB_AxB_rowscale.c
GB_to_nonhyper.c
GB_to_hyper.c

----------------------------------------------------------------------
mostly done:
----------------------------------------------------------------------

GB_AxB_parallel.c: much is done: mxm nicely parallel for large matrices,
    and decent parallelism for mxv when using the dot product.  This is where
    we do C=A*B, for GrB_mxm, GrB_mxv, and GrB_vxm.  *FINE slice methods are
    written but need tuning.  Need better fine-grain methods for mxv and vxm:
    do symbolic analysis phase (column nnz count), and then compute C in place
    without the final copy.  See for example *dot2.c. Need to do the same for
    Gustavson's method and for the Heap method.  Need to add the SLICE methods
    to the descriptor.  Need to write a hash-based method.

GB_AxB_flopcount.c: mostly done: reasonably implemented but needs a little work.
    Used by C=A*B for the parallel case, simple for all loop.  Note however the
    early exit, but this is only when nthreads == 1.  Currently, one thread has
    a 'continue' statement but if any thread terminates then all threads could
    break early.

GB_add.c: done, except for final prune of C->h, and the merge when 
    both A and B are hypersparse.  Modify to tolerate
    zombies on input, to make GB_wait faster?

GB_wait.c: done, except it might be updated when GB_add can tolerate zombies
    on input

GB_emult.c: done, except for final prune of C->h.

GB_mask.c: done, except for final prune of C->h

GB_cumsum.c: done, but not as fast as I think it should be.
    a parallel cumulative-sum.  Used many places.  Note the two variants.
    Performance of the parallel case is at most 2x speedup, unless the array is
    already in L3 cache.  Needs more work.

GB_transpose.c: done, except for the qsort.  uses two methods, a qsort-based
    method and a bucket sort.  Once the qsort is done, need to tune the auto
    selection betweeen the qsort and bucket sort.

GB_reduce_to_scalar.c: done, except needs a better terminal exit

----------------------------------------------------------------------
in progress
----------------------------------------------------------------------

Template/GB_qsort_template.c: IN PROGRESS
    Needs a way to set a larger leaf task size.
    Does lots of work, everywhere, for many GraphBLAS operations.
    Odd segfault with 20 threads.  see "TODO"

----------------------------------------------------------------------
not started
----------------------------------------------------------------------

GB_is_diagonal: determines if A is diagonal, for C=A*B.  Very little work to
    do, and can exit early as soon as it finds a vector k so that A(:,k)
    contains anything more than a single A(k,k) entry.  So it really needs
    a parallel early-exit.

GB_kron_kernel.c:
    Easy, with a 2-phase method.

----------------------------------------------------------------------
not started:  C=A(I,J) and C(I,J)=A
----------------------------------------------------------------------

GB_ijproperties.c: easy
    determines the properties of I and J for GB_subref_template and
    GB_subassign_kernel.

Template/GB_subref_template.c:
    Does the work for GrB_extract: A=C(I,J).  The list J can be partitioned and
    called in parallel to work on independent submatrices, like A1=C(I,J1)
    where J1 is the first set of columns in J.  Use a 2-phase method (phase1:
    count # entries, phase2: do the work).  Need to use fine tasks like
    GB_add, GB_emult, and GB_masker.  Note that J can have duplicates.

GB_subassign_kernel.c:
    This does C(I,J)=A (GrB_assign and GxB_subassign).  Huge file, but can be
    parallel since the main pass does not modify the pattern of C at all,
    except to kill entries by making them zombies.  If a new entry is to be
    added, it gets put into a list of pending tuples.  Each thread could make
    its own list, and the lists could be combined at the end.  This would be a
    single-phase method.

GB_assign.c:
    Does the work of GrB_*_assign.  Most of the work is in GB_subassign_kernel,
    but does work for the C_replace_phase, to create zombies in C outside of
    the IxJ submatrix.

GB_I_inverse.c:
    inverts the explicit list I for GB_subref_template.  A bucket sort; hard to
    parallelize the current algorithm.

GB_ijsort: deletes duplicates, see also GB_builder.  This is only used in
    GB_assign, for scalar expansion and for the C_replace_phase, and only when
    I and/or J are lists (not GrB_ALL, nor lo:inc:hi).

